{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../rawdata/hsa00001_20250311.json\") as f:\n",
    "    rawdata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_protein_str(protein_str):\n",
    "\n",
    "    parts = protein_str.split('\\t')\n",
    "\n",
    "    gene_info = parts[0].split(';')\n",
    "\n",
    "    gene_id = gene_info[0].split(' ')[0]\n",
    "    gene_symbol = gene_info[0].split(' ')[1]\n",
    "    gene_description = gene_info[1].strip()\n",
    "\n",
    "    return gene_id, gene_symbol, gene_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i in range(len(rawdata['children'])):\n",
    "    level1 = rawdata['children'][i]['name']\n",
    "    level1_info = rawdata['children'][i]['children']\n",
    "    for j in range(len(level1_info)):\n",
    "        level2 = level1_info[j]['name']\n",
    "        level2_info = level1_info[j]['children']\n",
    "        for k in range(len(level2_info)):\n",
    "            try:\n",
    "                level3 = level2_info[k]['name']\n",
    "                level3_info = level2_info[k]['children']\n",
    "                for protein in level3_info:\n",
    "                    protein_info = protein['name']\n",
    "\n",
    "                    gene_id, gene_symbol, gene_description = parse_protein_str(protein_info)\n",
    "\n",
    "                    data.append({\n",
    "                        'Level 1': level1,\n",
    "                        'Level 2': level2,\n",
    "                        'Level 3': level3,\n",
    "                        'Gene ID': gene_id,\n",
    "                        'Gene Symbol': gene_symbol,\n",
    "                        'Gene Description': gene_description\n",
    "                    })\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "data['KEGGID'] = data['Level 3'].str.extract(r'\\[PATH:(hsa\\d+)\\]')\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "data['Levels'] = data['Level 1'] + '---' + data['Level 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEGG_list = sorted(list(set(data['KEGGID'].unique().tolist())))\n",
    "KEGG_dict = {key: value+7854 for value, key in enumerate(KEGG_list)}\n",
    "\n",
    "with open('../preprocessed_data/KEGG_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(KEGG_dict, file)\n",
    "\n",
    "Target_dict = pd.read_pickle('../preprocessed_data/Target_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(KEGG_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kegg_protein = data[['Gene Symbol', 'KEGGID']].copy()\n",
    "data_kegg_protein['Gene Symbol'] = data_kegg_protein['Gene Symbol'].map(Target_dict)\n",
    "data_kegg_protein['KEGGID'] = data_kegg_protein['KEGGID'].map(KEGG_dict)\n",
    "data_kegg_protein = data_kegg_protein.dropna()\n",
    "data_kegg_protein['Gene Symbol'] = data_kegg_protein['Gene Symbol'].astype(int)\n",
    "data_kegg_protein.columns = ['node1', 'node2']\n",
    "data_kegg_protein['interaction'] = 12\n",
    "\n",
    "# data_kegg_protein.to_csv('../preprocessed_data/kegg_protein.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = list(KEGG_dict.values())[0]\n",
    "end = list(KEGG_dict.values())[-1]\n",
    "# nodes = list(range(start, end + 1))\n",
    "\n",
    "# edges = list(itertools.combinations(nodes, 2))\n",
    "\n",
    "# df = pd.DataFrame(edges, columns=['node1', 'node2'])\n",
    "\n",
    "# data['KEGG_id'] = data['KEGGID'].map(KEGG_dict)\n",
    "# keggid_to_level = dict(zip(data['KEGG_id'], data['Levels']))\n",
    "\n",
    "# df[\"level1\"] = df[\"node1\"].map(keggid_to_level)\n",
    "# df[\"level2\"] = df[\"node2\"].map(keggid_to_level)\n",
    "# df = df.dropna()\n",
    "# df[\"Type1_KEGG\"] = (df[\"level1\"] == df[\"level2\"]).astype(int)\n",
    "# df = df.drop(columns=[\"level1\", \"level2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_clean = data.dropna(subset=[\"KEGG_id\", \"Gene Symbol\"])\n",
    "\n",
    "# keggid_to_symbol = (\n",
    "#     data_clean.groupby(\"KEGG_id\")[\"Gene Symbol\"]\n",
    "#     .apply(set)        # 将同一KEGG_id的Gene Symbol转换为集合\n",
    "#     .to_dict()         # 转换为字典\n",
    "# )\n",
    "\n",
    "# df[\"symbol1\"] = df[\"node1\"].map(lambda x: keggid_to_symbol.get(x, set()))\n",
    "# df[\"symbol2\"] = df[\"node2\"].map(lambda x: keggid_to_symbol.get(x, set()))\n",
    "\n",
    "# df[\"interaction\"] = df.apply(\n",
    "#     lambda row: 13 if (row[\"symbol1\"] & row[\"symbol2\"]) else 0,\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# df = df.drop(columns=[\"symbol1\", \"symbol2\"])\n",
    "\n",
    "# df = df[df['interaction'] == 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = len(KEGG_dict)\n",
    "print(num_nodes)\n",
    "self_loops = pd.DataFrame({\n",
    "    'node1': range(start, end + 1),\n",
    "    'node2': range(start, end + 1),\n",
    "    'interaction': [14] * num_nodes\n",
    "})\n",
    "\n",
    "df_expanded = pd.concat([self_loops], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded.to_csv('../preprocessed_data/kegg.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg1 = pd.read_csv('../preprocessed_data/kg_v1.csv', index_col=None)\n",
    "kg2 = data_kegg_protein.copy()\n",
    "kg3 = df_expanded.copy()\n",
    "\n",
    "kg = pd.concat([kg1, kg2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_to_idx = pd.read_pickle('../preprocessed_data/interaction_to_idx.pkl')\n",
    "interaction_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = kg['interaction'].isin([3])\n",
    "subset = kg[mask].copy()\n",
    "subset['interaction'] = 8\n",
    "subset[['node1', 'node2']] = subset[['node2', 'node1']].values\n",
    "\n",
    "kg = pd.concat([kg, subset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = kg['interaction'].isin([5])\n",
    "subset = kg[mask].copy()\n",
    "subset['interaction'] = 9\n",
    "subset[['node1', 'node2']] = subset[['node2', 'node1']].values\n",
    "\n",
    "kg = pd.concat([kg, subset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = kg['interaction'].isin([6])\n",
    "subset = kg[mask].copy()\n",
    "subset['interaction'] = 10\n",
    "subset[['node1', 'node2']] = subset[['node2', 'node1']].values\n",
    "\n",
    "kg = pd.concat([kg, subset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = kg['interaction'].isin([7])\n",
    "subset = kg[mask].copy()\n",
    "subset['interaction'] = 11\n",
    "subset[['node1', 'node2']] = subset[['node2', 'node1']].values\n",
    "\n",
    "kg = pd.concat([kg, subset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = kg['interaction'].isin([12])\n",
    "subset = kg[mask].copy()\n",
    "subset['interaction'] = 13\n",
    "subset[['node1', 'node2']] = subset[['node2', 'node1']].values\n",
    "\n",
    "kg = pd.concat([kg, subset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = kg['interaction'].isin([1,2,4])\n",
    "subset = kg[mask].copy()\n",
    "subset['interaction'] += 0\n",
    "subset[['node1', 'node2']] = subset[['node2', 'node1']].values\n",
    "\n",
    "kg = pd.concat([kg, subset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg['interaction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.to_csv('../preprocessed_data/kg_v2.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
